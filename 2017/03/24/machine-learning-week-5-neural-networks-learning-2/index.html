
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Machine learning week 5 - Neural Networks: Learning</title>
    <meta name="description" content="">

    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="shortcut icon" href="../../../../favicon.ico">

    <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic%7COpen+Sans:700,400">
    <link rel="stylesheet" type="text/css" href="../../../../assets/css/screen.css?v=06e14b2c4c">


    <link rel="canonical" href="index.html">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <link rel="amphtml" href="amp/index.html">
    
    <meta property="og:site_name" content="Dong Liang's Blog">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Machine learning week 5 - Neural Networks: Learning">
    <meta property="og:description" content="Cost Function Neural network model Let's first define a few variables that we will need to use: L = total number of layers in the network sl = number of units (not counting bias unit) in layer l K = number of output units/classes Cost function Note: the double sum simply adds">
    <meta property="og:url" content="http://localhost:2368/2017/03/24/machine-learning-week-5-neural-networks-learning-2/">
    <meta property="article:published_time" content="2017-03-24T07:41:30.000Z">
    <meta property="article:modified_time" content="2017-04-01T02:02:42.000Z">
    <meta property="article:tag" content="machine learning">
    
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Machine learning week 5 - Neural Networks: Learning">
    <meta name="twitter:description" content="Cost Function Neural network model Let's first define a few variables that we will need to use: L = total number of layers in the network sl = number of units (not counting bias unit) in layer l K = number of output units/classes Cost function Note: the double sum simply adds">
    <meta name="twitter:url" content="http://localhost:2368/2017/03/24/machine-learning-week-5-neural-networks-learning-2/">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Dong Liang">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="machine learning">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Dong Liang&#x27;s Blog",
        "logo": "http://localhost:2368/ghost/img/ghosticon.jpg"
    },
    "author": {
        "@type": "Person",
        "name": "Dong Liang",
        "url": "http://localhost:2368/author/dong/",
        "sameAs": []
    },
    "headline": "Machine learning week 5 - Neural Networks: Learning",
    "url": "http://localhost:2368/2017/03/24/machine-learning-week-5-neural-networks-learning-2/",
    "datePublished": "2017-03-24T07:41:30.000Z",
    "dateModified": "2017-04-01T02:02:42.000Z",
    "keywords": "machine learning",
    "description": "Cost Function Neural network model Let&#x27;s first define a few variables that we will need to use: L &#x3D; total number of layers in the network sl &#x3D; number of units (not counting bias unit) in layer l K &#x3D; number of output units/classes Cost function Note: the double sum simply adds",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:2368"
    }
}
    </script>

    <script type="text/javascript" src="../../../../shared/ghost-url.js?v=06e14b2c4c"></script>
<script type="text/javascript">
ghost.init({
	clientId: "ghost-frontend",
	clientSecret: "25d5f7346569"
});
</script>
    <meta name="generator" content="Ghost 0.11">
    <link rel="alternate" type="application/rss+xml" title="Dong Liang's Blog" href="../../../../rss/index.html">
    <link rel="stylesheet" href="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/styles/github.min.css">
<script src="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head>
<body class="post-template tag-machine-learning nav-closed">

    <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="index.html#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
            <li class="nav-home"><a href="../../../../">Home</a></li>
            <li class="nav-machine-learning"><a href="../../../../tag/machine-learning/">Machine Learning</a></li>
    </ul>
        <a class="subscribe-button" href="../../../../subscribe/">Subscribe</a>
</div>
<span class="nav-cover"></span>


    <div class="site-wrapper">

        


<header class="main-header post-head no-cover">
    <nav class="main-nav  clearfix">
        
            <a class="menu-button icon-menu" href="index.html#"><span class="word">Menu</span></a>
    </nav>
</header>

<main class="content" role="main">
    <article class="post tag-machine-learning featured">

        <header class="post-header">
            <h1 class="post-title">Machine learning week 5 - Neural Networks: Learning</h1>
            <section class="post-meta">
                <time class="post-date" datetime="2017-03-24">24 March 2017</time>  on <a href="../../../../tag/machine-learning/">machine learning</a>
            </section>
        </header>

        <section class="post-content">
            <h3 id="costfunction">Cost Function</h3>

<p><strong>Neural network model</strong>
<img src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/04/scrn20160408215047.png" alt="neural network"></p>

<p>Let's first define a few variables that we will need to use:</p>

<ul>
<li>L = total number of layers in the network</li>
<li>sl = number of units (not counting bias unit) in layer l</li>
<li>K = number of output units/classes</li>
</ul>

<p><mark><strong>Cost function</strong></mark></p>

<p><img src="../../../../content/images/2017/03/Screen-Shot-2017-03-24-at-1.54.34-AM.png" alt="cost function"></p>

<p><strong><em>Note:</em></strong></p>

<ul>
<li>the double sum simply adds up the logistic regression costs calculated for each cell in the output layer</li>
<li>the triple sum simply adds up the squares of all the individual Θs in the entire network.</li>
<li>the i in the triple sum does not refer to training example i</li>
</ul>

<hr>

<h3 id="backpropagationalgorithm">Backpropagation Algorithm</h3>

<blockquote>
  <p>"Backpropagation" is neural-network terminology for minimizing our cost function. The goal of Backpropagation is to minimize J(theta) - the cost function of NN, using an optimal set of parameters in theta: namely minΘJ(Θ).</p>
</blockquote>

<p><strong>Backpropagation Intuition</strong></p>

<p><img src="../../../../content/images/2017/03/Screen-Shot-2017-03-31-at-3.35.53-PM.png" alt=""></p>

<p><em>*The δ(l)j is the error for a(l)j, expressed as the derivative of the cost function.The derivative is the slope of a line tangent to the cost fucntion, so the steeper the slope the more incorrect we are. *</em></p>

<p><img src="https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/qc309rdcEea4MxKdJPaTxA_324034f1a3c3a3be8e7c6cfca90d3445_fixx.png?expiry=1491091200000&amp;hmac=xP_kro6Z8DjXgkDS6Fldh99xn4GgBdcP0ffsNj7UUMs" alt=""></p>

<p>In the image above, to calculate δ(2)2, we multiply the weights Θ(2)12 and Θ(2)22 by their respective δ values found to the right of each edge. So we get δ(2)2= Θ(2)12<em>δ(3)1+Θ(2)22</em>δ(3)2. To calculate every single possible δ(l)j, we could start from the right of our diagram. We can think of our edges as our Θij. Going from right to left, to calculate the value of δ(l)j, you can just take the over all sum of each weight times the δ it is coming from. Hence, another example would be δ(3)2=Θ(3)12*δ(4)1.</p>

<hr>

<h3 id="unrollingparameters">Unrolling Parameters</h3>

<ul>
<li>It becomes more convenient when the theta or gradient parameters are packed into a bigger matrix, facilitating the vectorized operations. </li>
<li>Unrolling matrix of parameters and putting them into one long vector before using the optimizing function such as fminunc(). </li>
</ul>

<p><img src="https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/kdK7ubT2EeajLxLfjQiSjg_d35545b8d6b6940e8577b5a8d75c8657_Screenshot-2016-11-27-15.09.24.png?expiry=1491004800000&amp;hmac=qh2Gn1mRQ-khB5O2476dP0dkmXPypNn46ODoxmTmvHM" alt=""></p>

<hr>

<h3 id="gradientchecking">Gradient Checking</h3>

<p>Gradient Checking is designed to ensure that the deltaVector function works as intended. We can approximate the derivative of the cost function J(theta). </p>

<p>The approximation can be implemented by adding or subtracting epsilon to the theta matrix, as shown in octave codes as follows:</p>

<pre><code>epsilon = 1e-4;  
for i = 1:n,  
  thetaPlus = theta;
  thetaPlus(i) += epsilon;
  thetaMinus = theta;
  thetaMinus(i) -= epsilon;
  gradApprox(i) = (J(thetaPlus) - J(thetaMinus))/(2*epsilon)
end;  
</code></pre>

<hr>

<h3 id="randominitialization">Random Initialization</h3>

<p>The use of all-zero matrix for parameters initialization would result in repeated updating to the same values in all nodes during backpropagation. Random initialization of weights for theta matrix circumvent the problem of symmetry breaking.</p>

<p>Initializing weights with zeros for theta matrix doesn't work with neural network. When we backpropogate, the optimal values will update to the same values for all nodes. </p>

<p>Briefly, we initialize each theta with a random value between [-epsilon , epsilon]. Using this formula guarantees that we get the desired bound. We can apply the same technique to multi-dimentional J(theta) matrix. </p>

<pre><code>If the dimensions of Theta1 is 10x11, Theta2 is 10x11 and Theta3 is 1x11.

Theta1 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;  
Theta2 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;  
Theta3 = rand(1,11) * (2 * INIT_EPSILON) - INIT_EPSILON;  
</code></pre>

<hr>

<h3 id="puttingittogether">Putting it Together</h3>

<p>First, pick a network architecture; choose the layout of your neural network, including how many hidden units in each layer and how many layers in total you want to have.</p>

<ul>
<li>Number of input units = dimension of features x(i)</li>
<li>Number of output units = number of classes</li>
<li>Number of hidden units per layer = usually more the better (must balance with cost of computation as it increases with more hidden units)</li>
<li>Defaults: 1 hidden layer. If you have more than 1 hidden layer, then it is recommended that you have the same number of units in every hidden layer.</li>
</ul>

<p><strong>Training a Neural Network</strong></p>

<ol>
<li>Randomly initialize the weights  </li>
<li>Implement forward propagation to get hΘ(x(i)) for any x(i)  </li>
<li>Implement the cost function  </li>
<li>Implement backpropagation to compute partial derivatives  </li>
<li>Use gradient checking to confirm that your backpropagation works. Then disable gradient checking.  </li>
<li>Use gradient descent or a built-in optimization function to minimize the cost function with the weights in theta.</li>
</ol>

<pre><code>for i = 1:m,  
   Perform forward propagation and backpropagation using example (x(i),y(i))
   (Get activations a(l) and delta terms d(l) for l = 2,...,L
</code></pre>

<p>The codes showing an intuition of how gradient descent works as we are implementing our neural network. </p>

<p><img src="https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/hGk18LsaEea7TQ6MHcgMPA_8de173808f362583eb39cdd0c89ef43e_Screen-Shot-2016-12-05-at-10.40.35-AM.png?expiry=1491091200000&amp;hmac=HbE_ZEpKeYD2TltrrYVU5OxTmXQd83nuso-WkozYsoM" alt=""></p>

<p>The NN algorithm keeps iterating the data pool until it reaches local minimas where hΘ(x(i)) ~= y(i). The optimization process, as the the cost function is not convex, could generally results in local minimum instead of global minimum which causes trivial effect normally neglectable.</p>
        </section>

        <footer class="post-footer">



            <section class="author">
                <h4><a href="../../../../author/dong/">Dong Liang</a></h4>

                    <p>Read <a href="../../../../author/dong/">more posts</a> by this author.</p>
                <div class="author-meta">
                    
                    
                </div>
            </section>


            <section class="share">
                <h4>Share this post</h4>
                <a class="icon-twitter" href="https://twitter.com/intent/tweet?text=Machine%20learning%20week%205%20-%20Neural%20Networks%3A%20Learning&amp;url=http://localhost:2368/2017/03/24/machine-learning-week-5-neural-networks-learning-2/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <span class="hidden">Twitter</span>
                </a>
                <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:2368/2017/03/24/machine-learning-week-5-neural-networks-learning-2/" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <span class="hidden">Facebook</span>
                </a>
                <a class="icon-google-plus" href="https://plus.google.com/share?url=http://localhost:2368/2017/03/24/machine-learning-week-5-neural-networks-learning-2/" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <span class="hidden">Google+</span>
                </a>
            </section>

            <section class="gh-subscribe">
                <h3 class="gh-subscribe-title">Subscribe to Dong Liang's Blog</h3>
                <p>Get the latest posts delivered right to your inbox.</p>
                <form method="post" action="../../../../subscribe/index.html" class="">
    <input class="confirm" type="hidden" name="confirm"><input class="location" type="hidden" name="location"><input class="referrer" type="hidden" name="referrer">

    <div class="form-group">
        <input class="subscribe-email" type="email" name="email" placeholder="Your email address">
    </div>
    <button class="" type="submit">Subscribe</button>
    <script type="text/javascript">(function(g,h,o,s,t){h[o]('.location')[s]=h[o]('.location')[s] || g.location.href;h[o]('.referrer')[s]=h[o]('.referrer')[s] || h.referrer;})(window,document,'querySelector','value');</script>
</form>


                <span class="gh-subscribe-rss">or subscribe <a href="http://cloud.feedly.com/#subscription/feed/http://localhost:2368/rss/">via RSS</a> with Feedly!</span>
            </section>

        </footer>

    </article>
</main>

<aside class="read-next">
    <a class="read-next-story no-cover" href="../machine-learning-week-3-logistic-regression-2/">
        <section class="post">
            <h2>Machine learning week 3 - Logistic Regression</h2>
            <p>Summarize the lesson (Logistic Regression) Logistic regression is an updated version of linear regression featuring constraint prediction values with…</p>
        </section>
    </a>
    <a class="read-next-story prev no-cover" href="../../22/bayes-factors/">
        <section class="post">
            <h2>Bayes factors</h2>
            <p>Quoted from Wikipedia   In statistics, the use of Bayes factors is a Bayesian alternative to classical hypothesis testing.[1]…</p>
        </section>
    </a>
</aside>



        <footer class="site-footer clearfix">
            <section class="copyright"><a href="../../../../">Dong Liang's Blog</a> © 2017</section>
            <section class="poweredby">Proudly published with <a href="https://ghost.org">Ghost</a></section>
        </footer>

    </div>

    <script type="text/javascript" src="http://code.jquery.com/jquery-1.12.0.min.js"></script>
    <link rel="stylesheet" href="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/styles/github.min.css">
<script src="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
    <script type="text/javascript" src="../../../../assets/js/jquery.fitvids.js?v=06e14b2c4c"></script>
    <script type="text/javascript" src="../../../../assets/js/index.js?v=06e14b2c4c"></script>

</body>
